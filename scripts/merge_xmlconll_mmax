#!/usr/bin/env python2.7
# -*- coding: utf-8; -*-

"""
This script merges data from an annotated MMAX corpus with an XML file
containing CONLL data obtained by getting DG-trees from the same raw input that
was used for MMAX corpus.  The output is then plain CONLL data with annotations
from MMAX represented as features.
"""

##################################################################
# Libraries
import argparse
import os
import re
import sys
import string
import xml.etree.ElementTree as ET

from conll import CONLL, FEAT_NAME_SEP
from align import nw_align

##################################################################
# Constants
MS_PREFIX    = re.compile("\s*[$]")
# suffix of file with MMAX words
WFNAME_SFX   = re.compile("[.]words[.]xml$", re.IGNORECASE)
WSPAN_PREFIX = "word_"
# regexp matching spans encompassing multiple words
WMULTISPAN  = re.compile("{:s}(\d+)..+{:s}(\d+)".format(WSPAN_PREFIX, WSPAN_PREFIX), \
                                 re.IGNORECASE)
# regexp matching span encompassing single word
WSPAN       = re.compile("{:s}(\d+)\Z".format(WSPAN_PREFIX), re.IGNORECASE)
# regexp matching beginning of markable id's
MARK_ID_PRFX = re.compile("markable_(\d+)\Z", re.IGNORECASE)
# regexp representing all punctuation characters
PUNCT_RE = re.compile("[{:s}]".format(string.punctuation))
OFILE_EXTENSION = ".xml"
LINE_SEP = re.compile("\s*\n+\s*")
SPAN_SEP = ".."
SPAN_PRFX = "word_"
EOL = "EOL"

##################################################################
# Methods
def merge_xmlconll_mmax(xmlconlldoc, tkndoc, wrddoc, markable_paths):
    """Apply MMAX markables to CONLL data and output enriched CONLL string.

    @param conlldoc - XML corpus with CONLL data
    @param tkndoc   - path to file with original tokenization
    @param wrddoc   - path to MMAX words file
    @param markable_flist - list of files with markable annotations

    """
    # initialize auxiliary variables
    conll_t = conll_o = tkn_w = tkn_lw = mmax_w = mmax_lw = None
    mmax_w_id = i = 0
    conll_words = []
    mmax_words  = []
    conll_mmax_words = []       # aligned CONLL and MMAX annotations
    # create a dict for storing w_id => markable
    word2mark = dict()
    # populate dict of correspondences between words and markables
    markables2dict(markable_paths, word2mark)
    # establish an iterator over words in `wdoc`
    wrd_iter = wrddoc.iter("word")
    # iterate over tweets in `tkndoc`
    for t in tkndoc.iter("tweet"):
        # find CONLL trees corresponding to given tweet
        conll_t = xmlconlldoc.find('msg[@id="{:s}"]'.format(t.get("id")))
        # make sure that trees were actually found
        if conll_t == None:
            raise Exception("Tweet with id '{:s}' not found in CONLL corpus".format(t.get("id")))
        # parse CONLL data into a CONLL object
        conll_o = CONLL(conll_t.text)
        # get all CONLL words along with their sentence and word indices and
        # lowercase and strip these words
        conll_words = [(w.strip().lower(), s_id, w_id) for w, s_id, w_id in \
                           conll_o.get_words()]
        # set list of MMAX words to empty list
        mmax_words  = []
        # iterate over tweet's words, find their corresponding word ids in
        # wrddoc, and populate a list of 2-tuples in which the first element
        for tkn_w in t.text.strip().splitlines():
            tkn_lw = tkn_w.strip().lower()
            # retrieve corresponding MMAX word
            mmax_w = wrd_iter.next()
            # keep retrieving MMAX words until we hit first word which is not
            # end-of-line marker
            try:
                while mmax_w.text == EOL:
                    mmax_w = wrd_iter.next()
            except StopIteration:
                raise Exception("Number of token words is greater than number of MMAX words.")
            mmax_lw = mmax_w.text.strip().lower()
            # check that MMAX word corresponds to given tweet word
            if tkn_lw != mmax_lw:
                raise Exception(u"Token ('{:s}') and MMAX word ('{:s}') do not match".format( \
                        tkn_lw.encode("utf-8"), mmax_lw.encode("utf-8")))
            # add 2-tuple of tkn_lw and MMAX word id to the list of MMAX words
            mmax_words.append((tkn_lw, mmax_w.get("id")))
        # Align CONLL and MMAX word lists.  Result will be a list of three
        # elements tuples, in which first element will be sentence id of CONLL
        # word, second element will be word's id in that sentence, and the
        # third element will be a list of MMAX word ids corresponding to given
        # CONLL word
        conll_mmax_words = merge_conll_mmax(conll_words, mmax_words)
        # iterate over merged list and add annotation from MMAXX to
        # corresponding CONLL words
        for s_id, w_id, mmax_w_id_list in conll_mmax_words:
            # iterate over all MMAX words and add their id's
            for mmax_w_id in mmax_w_id_list:
                conll_o[s_id][w_id].add_features(word2mark.get(mmax_w_id, {}))
        # output enriched CONLL object
        print unicode(conll_o).encode("utf-8")

def merge_conll_mmax(conll_wlist, mmax_wlist):
    """Align elements from conll_wlist and mmax_wlist.

    conll_wlist's are lists of 3-tuples in which first element is conll word,
    second and third elements are sentence and word id of this word,
    respectively. mmax_list is a list of two tuples, in which first element is
    MMAX word and second element is MMAX id of this word.  This method
    determines to which CONLL word given MMAX corresponds and returns an
    augmented CONLL list whose tuples contain one additional 4-th element which
    is itself a list of MMAX word id's corresponding to given CONLL word.

    @param conll_wlist - list of 3-tuples with CONLL word, its sentence and word id
    @param mmax_wlist  - list of 2-tuples with MMAX word and its MMAX id

    @return list of three elements tuples, in which first element will be
        sentence id of CONLL word, second element will be word's id in that
        sentence, and the third element will be a list of MMAX word ids
        corresponding to given CONLL word

    """
    conll_words = [e[0] for e in conll_wlist]
    mmax_words  = [e[0] for e in mmax_wlist]
    s_id = w_id = 0
    mw_id_list = []
    # aligned_words will be a list of length len(conll_words) in which every
    # element will also be a list of the indices of mmax_words which correspond
    # to CONLL word at given position
    aligned_words = nw_align(conll_words, mmax_words)
    # join CONLL and MMAX indices
    ret = []
    for i, mwlist in enumerate(aligned_words):
        # append to `ret` a three-tuple with sentence and word indices of
        # CONLL word
        s_id, w_id = conll_wlist[i][1:]
        mw_id_list = [mmax_wlist[mw_id][1] for mw_id in mwlist]
        ret.append((s_id, w_id, mw_id_list))
    return ret

def markables2dict(markable_paths, word2mark_dict):
    """Read and parse markable documents populating word2mark dict.

    @param markable_paths - list of files with information about markables
    @param word2mark_dict - dictinoary which should be populated with
                            information about markables

    """
    # initialize auxiliary variables
    mdoc = mspan = attrs = None
    # parse markable documents and store their information in `markable_dict`
    for mp in markable_paths:
        # print >> sys.stderr, "Looking for markables in file", mp
        mdoc = ET.parse(mp)
        # due to presence of a namespace, we can't explicitly specify tags over
        # which we should iterate, so we look at their `span` attribute
        for mark in mdoc.iter():
            mspan = mark.get("span")
            if not mspan:
                continue
            # get attributes from markables, appropriately adjusting them
            attrs = __adjust_attrs__(mark.attrib)
            # populate dictionary of words with their corresponding markables
            for w_id in __parse_span__(mspan):
                # print >> sys.stderr, "Populating markables for word {:s}".format(w_id)
                # check that attributes in `attrs` do not intersect with those
                # already present in `word2mark_dict`
                assert(not (word2mark_dict.setdefault(w_id, dict([])).viewkeys() & attrs.viewkeys()))
                # add key/value pairs from `attrs` to `word2mark_dict[w_id]`
                word2mark_dict[w_id].update(attrs)

def __adjust_attrs__(attrdict):
    """Adjust attributes obtained from markables."""
    # all information from span has already been processed, so remove it
    attrdict.pop("span", None)
    # take id from attributes
    _id_ = attrdict.pop("id")
    # get `mmax_level` attribute
    mtype = __adjust_attr_key__(attrdict.pop("mmax_level"))
    # ok, now what's left are true attributes pertaining to given markable.
    # This markable, however, can coincide with another markable of the same
    # type and with the same set of attributes.  So, we need to make
    # attribute's name unambiguous by prepending them with the markable type
    # and its id
    attrdict = dict([(mtype + FEAT_NAME_SEP + _id_ + FEAT_NAME_SEP + __adjust_attr_key__(k), v) \
                    for k, v in attrdict.iteritems()])
    attrdict[mtype + FEAT_NAME_SEP + _id_ + FEAT_NAME_SEP + mtype] = "True"
    return attrdict

def __adjust_attr_key__(ikey):
    """Capitalize key's components and remove any punctuation from it."""
    return PUNCT_RE.sub("", ikey.title())

def __parse_span__(ispan):
    """Generate and return a list of all word ids encompassed by ispan."""
    if WSPAN.match(ispan):
        return [ispan]
    else:
        mobj = WMULTISPAN.match(ispan)
        if mobj:
            start, end = int(mobj.group(1)), int(mobj.group(2)) + 1
            return [(WSPAN_PREFIX + str(w_id)) for w_id in xrange(start, end)]
        else:
            raise ValueError("Unrecognized span format: {:s}".format(ispan))

def apply_annotation(wlist, wrd_iter, markable_hash):
    """Convert each word in wlist to a tuple and add annotation to it."""
    retlist = wfeatures = []
    w2 = ""
    w_id = None
    for w1 in wlist:
        w2 = wrd_iter.next()
        while w2.text == "EOL":
            w2 = wrd_iter.next()
        # print >> sys.stderr, "w1:", repr(w1)
        # print >> sys.stderr, "w2 text:", repr(w2.text)
        assert(w1 == w2.text)
        w_id = w2.get("id")
        if w_id in markable_hash:
            wfeatures = [f for f in markable_hash[w_id]]
        else:
            wfeatures = []
        retlist.append(tuple([w1] + wfeatures))
    return retlist

##################################################################
# Arguments
argparser = argparse.ArgumentParser(description="""Utility for merging
annotation from MMAX corpus with CONLL data stored in a separate XML file.""")
argparser.add_argument("xml_conll_file", help = "XML file with DG trees extracted from messages and represented in CONLL format within XML text fields")
argparser.add_argument("token_file", help = "file with original tokenization")
argparser.add_argument("word_file", help = "file with MMAX words")
argparser.add_argument("annotation_files", help = "files with MMAX markables", nargs = '*')
args = argparser.parse_args()

##################################################################
# Main

# skip files with no annotation
if not args.annotation_files:
    sys.exit(0)

# read and parse XML CONLL file
xmlconlldoc = ET.parse(args.xml_conll_file)
# read and parse tokenization file
tkndoc      = ET.parse(args.token_file)
# read and parse MMAX word file
wrddoc      = ET.parse(args.word_file)
# merge annotation with CONLL data
merge_xmlconll_mmax(xmlconlldoc, tkndoc, wrddoc, args.annotation_files)
