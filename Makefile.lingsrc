#############
# Variables #
#############
# Corpus
LINGBIN_DIR := ${SOCMEDIA_LINGBIN}
LINGTMP_DIR := ${SOCMEDIA_LINGTMP}

SRC_CORPUS  := ${SOCMEDIA_LINGSRC}/corpus/twitter_wulff.txt
PREPROCESSED_CORPUS := ${LINGTMP_DIR}/preprocessed_corpus.txt

# Add ${LINGBIN_DIR} to the list of automatically created directories
DIR_LIST += ${LINGBIN_DIR} ${LINGTMP_DIR}

###################
# Special Targets #
###################
.PHONY: corpus character_squeezer_stat \
	ngram_stat unigram_stat bigram_stat \
	topics topics_bernoulli topics_multinomial \
	sentiment \
	sentiment_corpus sentiment_corpus_train \
	sentiment_corpus_devtest sentiment_corpus_test sentiment_dict \
	clean_corpus \
	clean_character_squeezer_stat \
	clean_ngram_stat clean_topics \
	clean_sentiment \
	clean_sentiment_corpus clean_sentiment_corpus_train \
	clean_sentiment_corpus_devtest clean_sentiment_corpus_test \
	clean_sentiment_dict

.SECONDEXPANSION:

####################
# Specific Targets #
####################
# all_lingsrc
all_lingsrc: corpus character_squeezer_stat \
	ngram_stat topics sentiment

################
# clean_lingsrc
clean_lingsrc: clean_corpus clean_character_squeezer_stat \
	clean_ngram_stat clean_topics clean_sentiment

###############
# help_lingsrc
help_lingsrc:
	-@echo -ne "### Linguistic Resources ###\n\
	all_lingsrc   - compile linguistic components\n\
	corpus  - make preprocessed Twitter corpus\n\
	character_squeezer_stat   - gather statistics necessary for squeezing\n\
			            duplicated characters\n\
	ngram_stat - gather unigram and bigram statistics from corpus\n\
	unigram_stat - gather unigram statistics from corpus\n\
	bigram_stat  - gather bigram statistics from corpus\n\
	sentiment    - compile all data necessary for sentiment module\n\
	sentiment_corpus - prepare sentiment corpus for training and testing Alchemy\n\
	sentiment_dict - prepare list of sentiment polarity markers\n\
	topics       - gather statistics necessary for detection of topics\n\
	\n\
	clean_lingsrc - remove linguistic components\n\
	clean_corpus  - remove preprocessed corpus\n\
	clean_character_squeezer_stat - remove generated stat files for character_squeezer\n\
	clean_ngram_stat - gather unigram and bigram statistics from corpus\n\
	clean_unigram_stat - remove files with unigram statistics\n\
	clean_bigram_stat  - remove files with bigram statistics\n\
	clean_sentiment    - remove all temporary and compiled data pertaining to sentiment module\n\
	clean_sentiment_corpus - remove converted sentiment corpus\n\
	clean_sentiment_dict - remove lists with sentiment polarity markers\n\
	clean_topics - remove files created by topics\n\n" >&2

######################
# preprocessed_corpus
corpus: ${PREPROCESSED_CORPUS}

${PREPROCESSED_CORPUS}: ${SRC_CORPUS}
	set -e -o pipefail; \
	character_normalizer $^ | noise_cleaner -n | \
	slang_normalizer | umlaut_restorer | gawk 'NF{gsub(/[[:punct:]]+/, " "); \
	sub(/^[[:blank:]]+/, ""); sub(/[[:blank:]]$$/, ""); \
	gsub(/[[:blank:]][[:blank:]]+/, " "); print tolower($$0)}'  > '$@.tmp' && \
	mv '$@.tmp' '$@'

clean_corpus:
	-rm -f ${PREPROCESSED_CORPUS}

##########################
# character_squeezer_stat
CHAR_SQUEEZER_PICKLE := ${LINGBIN_DIR}/lengthened_stat.pckl

character_squeezer_stat: ${LINGBIN_DIR}/lengthened_stat.pckl | \
		    create_dirs

${CHAR_SQUEEZER_PICKLE}: ${PREPROCESSED_CORPUS}
	set -e ; \
	lengthened_stat $^ > '${@}.tmp' && mv '${@}.tmp' '$@'

clean_character_squeezer_stat: clean_corpus
	-rm -f ${LINGBIN_DIR}/lengthened_stat.pckl

#############
# ngram_stat
ngram_stat: unigram_stat bigram_stat

unigram_stat bigram_stat: %: ${LINGBIN_DIR}/%.pckl

unigram_stat: GRAM_SIZE := 1
bigram_stat:  GRAM_SIZE := 2

${LINGBIN_DIR}/unigram_stat.pckl ${LINGBIN_DIR}/bigram_stat.pckl: ${PREPROCESSED_CORPUS}
	set -e -o pipefail; \
	ngram_stat -n ${GRAM_SIZE} $< > $@.tmp && mv $@.tmp $@

clean_ngram_stat: clean_unigram_stat clean_bigram_stat

clean_unigram_stat clean_bigram_stat: clean_%: clean_corpus
	-rm -f ${LINGBIN_DIR}/$*.pckl

#################################
# topics
# number of topics to be distinguished
N_TOPICS := 40
TOPICS_CORPUS := ${LINGTMP_DIR}/topics_corpus.txt
TOPIC_MODEL_PICKLE = ${LINGBIN_DIR}/topics.%.pckl

topics: topics_bernoulli topics_multinomial

topics_bernoulli topics_multinomial: topics_% : ${TOPIC_MODEL_PICKLE}

${TOPIC_MODEL_PICKLE}: ${TOPICS_CORPUS}
	set -e; \
	topics_train_parameters '--model=$*' --number-of-topics=${N_TOPICS} \
	'$<' > '$@.tmp' && mv '$@.tmp' '$@'

${TOPICS_CORPUS}: ${SRC_CORPUS} ${CHAR_SQUEEZER_PICKLE}
	set -e; \
	topics_train_corpus '$<' > '$@.tmp' && \
	mv '${@}.tmp' '$@'

clean_topics:
	-rm -f '${TOPICS_CORPUS}' ${LINGBIN_DIR}/topics*

############
# sentiment
sentiment: sentiment_corpus sentiment_dict

clean_sentiment: clean_sentiment_corpus clean_sentiment_dict

#################################
# sentiment corpus
SENTIMENT_CORPUS_ROOT := ${SOCMEDIA_LINGSRC}/corpus/sentiment/twitter
SENTIMENT_CORPUS_SRC  := ${SENTIMENT_CORPUS_ROOT}/twitter.sentiment.xml
# MMAX-related stuff
SENTIMENT_CORPUS_MMAX_ROOT := ${SENTIMENT_CORPUS_ROOT}/mmax-prj
SENTIMENT_CORPUS_MMAX_ORIG := ${SENTIMENT_CORPUS_MMAX_ROOT}/source
SENTIMENT_CORPUS_ORIG_SFX  := .xml
SENTIMENT_CORPUS_MMAX_BASE := ${SENTIMENT_CORPUS_MMAX_ROOT}/basedata
SENTIMENT_CORPUS_BASE_SFX  := .words${SENTIMENT_CORPUS_ORIG_SFX}
SENTIMENT_CORPUS_MMAX_ANNO := ${SENTIMENT_CORPUS_MMAX_ROOT}/markables
# target directory for storing corpus
SENTIMENT_CORPUS_TRGDIR  := ${LINGTMP_DIR}/corpus/sentiment
DIR_LIST += ${SENTIMENT_CORPUS_TRGDIR}
# corpus with CONLL trees
SENTIMENT_CONLL_CORPUS := ${SENTIMENT_CORPUS_TRGDIR}/corpus.sentiment.conll.xml
# directories for storing training, development, and test corpora
SENTIMENT_CORPUS_TRAINDIR   := ${SENTIMENT_CORPUS_TRGDIR}/train
SENTIMENT_CORPUS_DEVTESTDIR := ${SENTIMENT_CORPUS_TRGDIR}/devtest
SENTIMENT_CORPUS_TESTDIR    := ${SENTIMENT_CORPUS_TRGDIR}/test
# directory for storing DB files
SENTIMENT_CORPUS_DBDIR   := ${SENTIMENT_CORPUS_TRGDIR}/db
SENTIMENT_CORPUS_DBSFX   := .db
# DB files are the same as `.xml' files in `${SENTIMENT_CORPUS_MMAX_BASE}',
# but they are stored in directory $(SENTIMENT_CORPUS_DBDIR) and have
# extension `.db'
SENTIMENT_CORPUS_DBFILES := $(addprefix $(SENTIMENT_CORPUS_DBDIR)/, \
	$(addsuffix $(SENTIMENT_CORPUS_DBSFX), \
	$(notdir $(basename $(wildcard $(SENTIMENT_CORPUS_MMAX_ORIG)/*.xml)))))
# add automatically created directories to the list of automatic
# directories
DIR_LIST += ${SENTIMENT_CORPUS_TRAINDIR} ${SENTIMENT_CORPUS_DEVTESTDIR} \
	    ${SENTIMENT_CORPUS_TESTDIR} ${SENTIMENT_CORPUS_DBDIR}

# divide DB files in train, cross validation, and test sets
sentiment_corpus: ${SENTIMENT_CORPUS_DBFILES}

# create DB files (DO NOT change the order of pre-requisites)
${SENTIMENT_CORPUS_DBFILES}: ${SENTIMENT_CORPUS_DBDIR}/%${SENTIMENT_CORPUS_DBSFX}: \
	${SENTIMENT_CONLL_CORPUS} ${SENTIMENT_CORPUS_MMAX_ORIG}/%${SENTIMENT_CORPUS_ORIG_SFX} \
	${SENTIMENT_CORPUS_MMAX_BASE}/%${SENTIMENT_CORPUS_BASE_SFX} \
	$$(wildcard $(SENTIMENT_CORPUS_MMAX_ANNO)/%_*)
	set -e -o pipefail; \
	merge_xmlconll_mmax $^ | conll2db > $@.tmp && mv $@.tmp $@

# extract DG trees from raw unannotated sentiment corpus
${SENTIMENT_CONLL_CORPUS}: ${SENTIMENT_CORPUS_SRC}
	set -e; \
	xml2tsv $< | TextTagger --no-lang-filter | TextParser -t > $@.tmp && \
	mv $@.tmp $@

# do the clean-up
clean_sentiment_corpus:
	-rm -f ${SENTIMENT_CORPUS_DBFILES} ${SENTIMENT_CONLL_CORPUS}

#######################
# sentiment dictionary
# (macro expansion of SentiWS)
SENTIMENT_DICT_SRCDIR := ${SOCMEDIA_LINGSRC}/sentiment_dict
SENTIMENT_DICT_FILES  := ${LINGTMP_DIR}/negative.txt ${LINGTMP_DIR}/positive.txt

sentiment_dict: create_dirs ${SENTIMENT_DICT_FILES}

# Note, that gawk's functions are locale aware, so setting locale to
# utf-8 will correctly lowercase input letters
${SENTIMENT_DICT_FILES}: ${LINGTMP_DIR}/%.txt: ${SENTIMENT_DICT_SRCDIR}/%.azm \
					      ${SOCMEDIA_LINGSRC}/defines.azm
	set -e -o pipefail; \
	test "$${LANG##*\.}" == "UTF-8" && zoem -i "${<}" -o - | \
	gawk -F "\t" -v OFS="\t" '/^##!/{print; next}; NF {sub(/(^|[[:space:]]+)#.*$$/, "")} \
	$$0 {$$1 = tolower($$1); print}' > "${@}.tmp" && \
	mv "${@}.tmp" "${@}"

clean_sentiment_dict:
	-rm -f ${SENTIMENT_DICT_FILES}

