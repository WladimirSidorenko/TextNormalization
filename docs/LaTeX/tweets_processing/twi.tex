\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{latin1}
\usepackage[T1]{fontenc} % fuer accent circonflex ueber i, Trennung mit Umlaut
\usepackage{german}
\usepackage{scrpage2}
\usepackage{epsf}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{makeidx}
\usepackage{booktabs}
\usepackage{rotating}
\usepackage{tabularx}
\usepackage{covingtn}
\usepackage{enumitem}
\usepackage{ae}
\usepackage[comma,round]{natbib}
\usepackage{url}
\usepackage{a4nicer}
%\usepackage{palatino}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Automatische Verarbeitung deutschsprachiger Tweets:\\ Eine Fallstudie}

%\author{{Manfred Stede\\ Applied Computational
%  Linguistics\\Department of Linguistics\\ University of Potsdam
%  (Germany)\\{\tt stede@uni-potsdam.de}} \and {Kristin Irsig\\ID Berlin}}

\author{}
%Manfred Stede\\ Applied Computational
%  Linguistics\\ University of Potsdam\\ {\tt
%  stede@uni-potsdam.de} \and Kristin Irsig\\ ID Information und
%  Dokumentation\\ im Gesundheitswesen GmbH \&Co. KGAA\\ Berlin\\ {\tt K.Irsig@id-berlin.de}}

\date{}

\pagestyle{empty}


\begin{document}

\maketitle

\thispagestyle{empty}

%\begin{abstract}
%\noindent Abstrakt.
%\end{abstract}



\section{Einführung}

TODO: DIE BESONDERHEITEN DES TWEET PROCESSING


% ======================================================================
\section{Zielsetzung}

Das Projekt ``Diskurse in Social Media'' untersucht aus
kommunikationswissenschaftlicher Perspektive den Verlauf von
politischen Diskursen in drei verschiedenen Social Media: Twitter,
Facebook und Blogs. Es wird untersucht, inwieweit sich zwischen diesen
drei Medien Unterschiede finden lassen im Hinblick auf
\begin{itemize}
\item den zeitlichen Verlauf von Debatten: Wie entwickelt sich das
  Volumen einer Diskussion?
\item die Dialogizität der Diskurse: Wie gehen Teilnehmer auf die
  Beiträge anderer Teilnehmer ein?
\item die Meinungsführerschaft: Sind bestimmte Akteure in den
  Diskussionen ``tonangebend''?
\item die Themen: Welche Aspekte des Themenkreises werden diskutiert?
\item die Meinung: Welche Stimmungslage kommt in einer Diskussion zum Ausdruck?
\end{itemize}
Die qualitativ hochwertige Analyse dieser Fragestellungen setzt das
sachkundige menschliche Urteil voraus, das heißt: am Ende der
Bemühungen steht eine Inhaltsanalyse durch ausgebildete Analysten. Die
Projektpartner aus der Wirtschaftsinformatik und der
Computerlinguistik sollen diesen Prozess aber maßgeblich unterstützen,
um bei einem relativ umfangreichen Datensatz die menschliche Analyse
auf die relevanten Beiträge konzentrieren zu können. Als erstes
Arbeitskorpus wurden dazu Daten ausgewählt, die im Jahr 2011 über
einen Zeitraum von zwei Wochen hinweg (TODO: stimmt das? - wenn die
Angabe 12.12-17.02 im Dateinamen des Korpus den Zeitraum des
Textsammelns bedeutet, so d\"urften es gut 2 Monate sein) das
Stichwort `Wulff' beinhalten, also höchstwahrscheinlich Äußerungen zur
Affäre um den seinerzeitigen Bundespräsidenten beinhalten. Im
vorliegenden Beitrag beschränken wir uns auf die Twitter-Daten, das
sind 119 455 einzelne Tweets, von denen wir zunächst 28 818 als
Duplikate idetifiziert haben; somit verbleibt eine Grundmenge von 90
637 zu verarbeitenden Tweets.

Im Projekt sind die Wirtschaftsinformatiker für die Beschaffung der
Datensätze und die Konstruktion von Graphstrukturen zuständig, die die
Verweise zwischen Diskussionsbeiträgen abbilden. Der
Computerlinguistik obliegt die inhaltliche Analyse der einzelnen
Beiträge im Hinblick auf behandelte Themen und die Stimmungslage: Es
wird eine ``Vorsortierung'' der Beiträge durchgeführt, um im Idealfall
die Aufgabe der Analysten auf eine zügige Durchsicht beschränken zu
können. Die Vorsortierung erfolgt anhand drier Dimensionen:
\begin{itemize}
\item Themenklassifikation: Durch unüberwachte Verfahren wird ein
  Clustering von Beiträgen im Hinblick auf (Unter-) Themen
  vorgenommen.\\ Hier einige Beispiele aus dem Wulff-Korpus, die das
  Adressieren verschiedener Themen illustrieren: TODO
\item Sentimentklassifikation: Für jeden Einzelbeitrag soll erkannt
  werden, ob eine positive, negative oder neutrale Haltung ausgedrückt
  wird. Korpus-Beispiele: TODO\\ Zusätzlich soll im Falle von Verweisen auf andere Beiträge
  festgestellt werden, ob diese zustimmend, kritisch, oder neutral
  ausfallen. Korpusbeispiele: TODO
\item Diskursqualitätklassifikation: Textbeiträge können inhaltlich
  fundiert sein und das Potenzial haben, eine Diskussion fruchtbar
  voranzubringen, oder lediglich kurze ``Einwürfe''
  darstellen. Korpusbeispiele: TODO
\end{itemize}


% ======================================================================
\section{Die Pipeline zur Vorverarbeitung}

TODO:
\subsection{Sprachidentifikation}

Die von den Wirtschaftsinformatikern zusammengestellten Daten
enthalten noch tweets, die nicht in deutscher Sprache abgefasst
sind. Um diese zu filtern, haben wir mit drei {\em off-the-shelf}
Werkzeugen zur Sprachidentifikation experimentiert.

\begin{itemize}
\item LangId, TODO: weiß man wie er arbeitet?
\item Textcat
\item LangGuess
\end{itemize}

Um die Präzision der Spracherkennung der o.g. Tools einzuschätzen,
sind wir dabei folgenderweise vorgegangen. Alle Tweets, die einstimmig
von allen 3 Programmen, als deutsch bzw. nicht-deutsch interpretiert
wurden, wurden bewusst außer Betracht gelassen. Denn sie hätten die
Entscheidung für die jeweilige Software-Lösung sowieso nicht
beeinflussen können. Von den übrig gebliebenen 5962 Tweets wurden
10\%{} (d.h. 596 Tweets) zufällig ausgewählt und die Richtigkeit der
geratenen Sprachen bei ihnen manuell gerprüft. Die Ergebnisse dieser
Evaluierung werden in der Tabelle unten zusammengefasst:

\begin{table}{|c|c|c|}
\hline
\multicolumn{3}{|c|}{Prozentrate korrekt getroffener Entscheidungen\newline \textit{(Precision)}}\\\hline
LangId & Textcat & LangGuess \\\hline
92.97\%{} & 61.34\%{} & 35.5\%{} \\\hline
\end{table}

\subsection{Satzgrenzenerkennung}

Die generelle Arbeitsweise eines ``sentence splitters'' besteht darin,
Punkte am Ende eines Wortes dahingehend zu disambiguieren, ob es sich
um einen Satzende-Punkt oder den Bestandteil einer Abkürzung (wie
z.B. in ``Nr. 3''), einer Datumsangabe o.ä. handelt. Bei
Tweet-Processing wurden aßerdem noch zusätzliche zum Teil störende
Faktoren festgestellt, die eine Anpassung der Modulregeln an dieses
Textgenre notwendig machten, wie z.B:
\begin{itemize}
  \item Retweet-Markierungen, die in vielen Fällen in Tweets anstelle eines
    Punktes Sätze voneinander abgrenzen;
  \item Missachtung von Groß- und Kleinschreibungsregeln;
  \item Abgrenzung von Sätzen durch Gedanken- und Schrägstriche.
\end{itemize}

\subsection{Normalisierung und Tokenisierung}

\subsubsection{Zu behandelnde Phänomene}

TODO: Klassifizierte Liste von Dingen, die man behandeln muss

\subsubsection{Vorgehen}


\subsection{Part-of-speech tagging}

In our evaluation experiments we compared TreeTagger and TNT by randomly choosing 1000 tweets from Twitter Wulff corpus. These tweets were subsequently run through the taggers pre-processed with same tokenizer (TreeTagger's Perl Tokenizer). Taggers showed difference in 3351 from input 19649 words (what roughly made 17\% of total number of tokens). The results of evaluation are depicted in the table below:

\begin{tabular}{|*{6}{p{0.15\textwidth}|}}\hline
\multicolumn{6}{|c|}{Tagger Comparison}\\\hline\hline
\multicolumn{3}{|c|}{Tree Tagger}&\multicolumn{3}{c|}{TNT Tagger}\\\hline
Chosen Better Tag&Opposite Worse Tag & \# of Cases & Chosen Better Tag & Opposite Worse Tag & \# of Cases\\\hline
NE & NN & 312 & NE & NN & 387\\
NN & ADJD & 122 & VVINF & VVFIN & 48\\
NN & VVFIN & 81 & NN & ADJD & 45\\
NN & ADJA & 80 & NE & ADJA & 37\\
NN & NE & 65 & NN & ADJA & 35\\
NE & ADJD & 64 & NN & NE & 32\\
NE & VVFIN & 51 & \$( & ADJA & 31\\
NE & XY & 48 & FM & NE & 21\\
VVFIN & VVPP & 33 & FM & NN & 17\\
NN & CARD & 33 & PWS & PIS & 17\\
... & ... & ... & ... & ... & ...\\

\multicolumn{2}{|c|}{Total better choices:} & \textbf{1530} & \multicolumn{2}{|c|}{Total better choices:} & \textbf{1083}\\\hline\hline
\multicolumn{5}{|l|}{Differences found:}& \textbf{3338}\newline \small{(16.99\% of tokens)}\\\hline
\multicolumn{5}{|l|}{Differences considered irrelevant:}& \textbf{725}\\\hline
\multicolumn{5}{|l|}{Sentences tested:}& \textbf{1000}\\\hline
\end{tabular}

% ======================================================================
\section{Inhaltsklassifikation / Auswertung}

\subsection{Koreferenz}
Für eine genauere Analyse des Tweet-Inhalts auf der Satzebene soll
eine Koreferenzresolution vorgenommen werden.

TODO:
\begin{itemize}
\item Wieviele Pronomen finden wir?
\item Wieviele sonstige Korefs?
\item Wie ist die Performanz von PoCoRes?
\item Performanz auf normalisiertem Input?
\item Was sind die typischen Fehler?
\item Perspektive: wie weiter? Ist twitter-Koref einfacher als
  generelle Koref? Was dürfte ein vielversprechendes Verfahren sein?
\end{itemize}

\subsection{``Off-topic''}
Die Datenerhebung geschah im Wesentlichen durch keyword matching:
Beinhaltet ein tweet das Wort `Wulff'? Dadurch können gelegentlich
tweets in die Suchmenge gelangen, die thematisch nicht relevant sind,
weil sie sich auf eine andere Person gleichen Namens beziehen.\\
TODO: Beispiel\\
TODO: Kommt das häufig vor?\\
TODO: Wie gehen wir damit um?

\subsection{Subtopiks}

\subsection{Sentiment}

\subsection{Diskursqualität}

% ======================================================================
\section{Zusammenfassung}





%-------------------------------------------------------
\bibliographystyle{named}
\begin{small}
\bibliography{ALLmar130309}
\end{small}

\end{document}
